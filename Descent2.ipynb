{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Descent (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digging at the lowest point of Olduvai Gorge, you discover a hatch:\n",
    "\n",
    "![Hatch](./img/hatch.jpg)\n",
    "\n",
    "You descend a ladder into the hatch until you reach a sloped surface. Armed only with a GPS and torch (both the light source and the Python matrix manipulation package), you can't really see much beyond your own two feet. Luckily, you've studied gradient descent algorithms, so you know what to do.\n",
    "\n",
    "You begin by establishing an interface for the unlit environment you find yourself in, noting that you can do the following:\n",
    "\n",
    "- determine your current (x,y) position\n",
    "- determine the gradient at a particular (x,y) position\n",
    "- step to a new (x,y) position\n",
    "- determine whether you can see the exit (the lowest point)\n",
    "- determine your current status (actively searching, found the exit)\n",
    "\n",
    "Here is the interface:\n",
    "\n",
    "```\n",
    "class Environment:      \n",
    "    def current_position(self):\n",
    "        \"\"\"\n",
    "        Returns your current (x,y) position.\n",
    "        \n",
    "        The return value is a 2-dimensional torch.tensor, e.g.\n",
    "        torch.tensor([x,y]).        \n",
    "        \"\"\"\n",
    "        \n",
    "    def gradient(self, position):\n",
    "        \"\"\"\n",
    "        Returns the gradient at a particular position.\n",
    "        \n",
    "        position is a 2-dimensional torch.tensor, e.g. torch.tensor([x,y])\n",
    "          where (x,y) is the current position\n",
    "          \n",
    "        The return value is also a 2-dimensional torch.tensor.        \n",
    "        \"\"\"\n",
    "        \n",
    "    def step_to(self, position):\n",
    "        \"\"\"\n",
    "        Changes your current (x,y) position to the new position.\n",
    "        \n",
    "        position is a 2-dimensional torch.tensor, e.g. torch.tensor([x,y]).        \n",
    "        \"\"\"\n",
    "\n",
    "    def can_see_exit(self, position):\n",
    "        \"\"\"\n",
    "        Returns True if you can see the exit from the specified position.        \n",
    "        \"\"\"\n",
    "        \n",
    "    def status(self):\n",
    "        \"\"\"\n",
    "        Returns the current status of your search.\n",
    "        \n",
    "        - Environment.ACTIVELY_SEARCHING means that the search is still active.\n",
    "        - Environment.EXCEEDED_STEP_LIMIT means that you have exceeded the\n",
    "          maximum number of steps that you are willing to take\n",
    "        - Environment.FOUND_EXIT means that you have found the lowest point\n",
    "          of the environment.\n",
    "        \"\"\"\n",
    "```    \n",
    "\n",
    "\n",
    "Note that you're a little frightened of the dark, so you decide that you won't take more than 100 steps before retreating back to the entry hatch and trying a new strategy. This is tracked by the environment, which returns the status EXCEEDED_STEP_LIMIT if you've taken too many steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import levels\n",
    "from levels import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also would like a way to visualize your steps, so you make the following plotting functions using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize_journey(positions, found_destination):\n",
    "    \"\"\"\n",
    "    Plots a series of (x,y) positions. The first point is orange, the intermediate points are gray, and the\n",
    "    final point is green or red, depending (respectively) on whether the destination has or has not been found.\n",
    "    \n",
    "    positions is a list of 2-dimensional torch.tensors\n",
    "    found_destination is a boolean indicating whether the destination was found\n",
    "    \n",
    "    \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for pt in positions:\n",
    "        xs.append(pt[0].item())\n",
    "        ys.append(pt[1].item())\n",
    "    plt.scatter(xs, ys, color='gray')\n",
    "    plt.plot(xs, ys, color='gray')\n",
    "    plt.scatter([0], [0], color='orange')\n",
    "    if found_destination:\n",
    "        final_color = 'lime'\n",
    "    else:\n",
    "        final_color = 'red'\n",
    "    plt.scatter([positions[-1][0].item()], [positions[-1][1].item()], color=final_color)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, here is the visualization of a journey that begins at point (0,0), then proceeds to points (3,1), (6,-1), and (5,-2), without finding the exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "positions = [tensor([0.0, 0.0]), tensor([3.0, 1.0]), tensor([6.0, -1.0]), tensor([5.0, -2.0])]\n",
    "visualize_journey(positions, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a general-purpose gradient descent algorithm, so that you can start exploring the environment. Specifically, complete the function ```grad_descent``` in ```algorithms.py```, according to the specifications in its comments.\n",
    "\n",
    "There's a unit test in test.py, so that you can check your algorithm is working properly. Run it from the command line as follows:\n",
    "\n",
    "    python -m unittest test.GradientDescentTests.test_vanilla\n",
    "    \n",
    "Once it's working, you should be ready to find the lowest point in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import vanilla_grad_descent\n",
    "env = levels.Level1()\n",
    "points = vanilla_grad_descent(0.95, env)\n",
    "if len(points[1:]) == 51:\n",
    "    visualize_journey(points, env.can_see_exit(points[-1]))\n",
    "else:\n",
    "    print(\"Looks like there's still a bug in your grad_descent code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a mere 51 steps, you catch sight of yet another hatch:\n",
    "\n",
    "![Hatch](./img/hatch2.jpg)\n",
    "\n",
    "You take another ladder down into yet another dark environment. Well, it worked last time, so let's try vanilla gradient descent once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = levels.Level2()\n",
    "points = vanilla_grad_descent(0.95, env)\n",
    "visualize_journey(points, env.can_see_exit(points[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 100 steps, you still haven't found the exit, so you retrace your steps back to the entrance. Visualizing your previous journey, it seems like you're in a narrow ravine with steeply sloping sides, which is causing you to go back and forth sharply across the width of the ravine, but not make much forward progress along its length. You've read about this phenomenon in class, and remember that one way to deal with it is to use gradient descent with *momentum*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the implementation of gradient descent with momentum (```momentum_grad_descent```) in ```algorithms.py```, according to the specifications in its comments.\n",
    "\n",
    "Again we've provided a unit test in test.py, so that you can check your algorithm is working properly. Run it from the command line as follows:\n",
    "\n",
    "    python -m unittest test.GradientDescentTests.test_momentum\n",
    "    \n",
    "Confident in your test-passing implementation, you steel yourself and head into the darkness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import momentum_grad_descent\n",
    "env = levels.Level2()\n",
    "points = momentum_grad_descent(0.95, env)\n",
    "if len(points[1:]) == 93:\n",
    "    visualize_journey(points, env.can_see_exit(points[-1]))\n",
    "else:\n",
    "    print(\"Looks like there's still a bug in your grad_descent code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 93 steps, you find a third hatch:\n",
    "\n",
    "![Hatch](./img/hatch3.jpg)\n",
    "\n",
    "Again, you go down. You try a few steps of gradient descent with momentum..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = levels.Level3()\n",
    "points = momentum_grad_descent(0.95, env)\n",
    "visualize_journey(points, env.can_see_exit(points[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but quickly realize you're spinning out of control (notice the scale of the axes). It seems that your step size is too large. You go back to vanilla gradient descent with a smaller step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = levels.Level3()\n",
    "points = vanilla_grad_descent(0.05, env)\n",
    "visualize_journey(points, env.can_see_exit(points[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, you find another hatch. Hopefully this the last one.\n",
    "\n",
    "![Hatch](./img/hatch4.jpg)\n",
    "\n",
    "You try out vanilla gradient descent with the same conservative step size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = levels.Level4()\n",
    "points = vanilla_grad_descent(0.05, env)\n",
    "visualize_journey(points, env.can_see_exit(points[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 100 steps, you declare defeat and go back to the entrance. You're a bit tired of guessing the correct step size, so you'd like to try a gradient descent method with an adaptive step size (i.e. one where the step size is a function of time). You can't help but notice that the slopes of this level aren't particularly smooth. You proceeded directly east for a long time before the gradient started leading you south. Therefore you don't want to use an adaptive method where the step size decreases in all dimensions at the same rate, because by the time you reach the south-leading slope, your step size would likely be too tiny to make any good progress.\n",
    "\n",
    "Luckily, you remember AdaGrad is a gradient descent method where the rate changes independently in each dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Complete the implementation of AdaGrad (```adagrad```) in ```algorithms.py```, according to the specifications in its comments.\n",
    "\n",
    "We've provided a unit test in test.py, so that you can check your algorithm is working properly. Run it from the command line as follows:\n",
    "\n",
    "    python -m unittest test.GradientDescentTests.test_adagrad\n",
    "    \n",
    "Confident in your implementation, you try navigating the fourth level again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import adagrad\n",
    "env = levels.Level4()\n",
    "points = adagrad(0.95, env)\n",
    "if len(points[1:]) == 101:\n",
    "    visualize_journey(points, env.can_see_exit(points[-1]))\n",
    "else:\n",
    "    print(\"Looks like there's still a bug in your adagrad code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like you're close, but no cigar. You seem to remember learning that AdaGrad can sometimes converge too quickly, and that RmsProp might be a better choice for some topologies. Looks like it's back to implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Complete the implementation of RmsProp (```rmsprop```) in ```algorithms.py```, according to the specifications in its comments.\n",
    "\n",
    "We've provided a unit test in test.py, so that you can check your algorithm is working properly. Run it from the command line as follows:\n",
    "\n",
    "    python -m unittest test.GradientDescentTests.test_rmsprop\n",
    "    \n",
    "Third time's the charm! You head out again, into the darkness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import rmsprop\n",
    "env = levels.Level4()\n",
    "points = rmsprop(0.4, 0.95, env)\n",
    "if len(points[1:]) == 35:\n",
    "    visualize_journey(points, env.can_see_exit(points[-1]))\n",
    "else:\n",
    "    print(\"Looks like there's still a bug in your rmsprop code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, there's no hatch, just a weird chest.\n",
    "\n",
    "![Chest](./img/chest.jpg)\n",
    "\n",
    "You open it. There inside is the magnificent Chekhov's Sun. But what are you planning to do with the world's largest yellow diamond? After correctly implementing four different gradient descent algorithms, the answer should be easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer():\n",
    "    points = vanilla_grad_descent(0.95, levels.LevelX())\n",
    "    points2 = momentum_grad_descent(0.95, levels.LevelX())\n",
    "    points3 = adagrad(0.95, levels.LevelX())\n",
    "    points4 = rmsprop(0.4, 0.95, levels.LevelX())\n",
    "    ALPHABET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    letter1 = ALPHABET[int(points[3][0].item()) - 11]\n",
    "    letter2 = ALPHABET[int(points2[3][0].item()) - 8]\n",
    "    letter3 = ALPHABET[int(points3[3][0].item()) + 16]\n",
    "    letter4 = ALPHABET[int(points4[3][0].item())]\n",
    "    letter5 = ALPHABET[int(points2[5][0].item()) - 20]\n",
    "    letter6 = ALPHABET[int(points4[5][0].item()) + 7]\n",
    "    word = '{}{}{}{}{}{}'.format(letter1, letter2, letter3, letter4, letter5, letter6)\n",
    "    return word\n",
    "\n",
    "def submit(response):\n",
    "    import rpyc\n",
    "    c = rpyc.connect(\"134.10.103.248\", 18861)\n",
    "    return c.root.submit_response('q2', response)\n",
    "\n",
    "print('You submit the password {} to the server.'.format(answer()))\n",
    "submit(answer())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
